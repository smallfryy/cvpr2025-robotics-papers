# CVPR 2025 Robotics Papers

A curated list of ~100 robotics / robotics-adjacent research papers presented at CVPR 2025. 

This year’s themes include robot manipulation, vision-language models, simulation, human-robot interaction, 3D perception, motion prediction, and embodied AI agents. Explore interactive papers on [Bytez](https://bytez.com/search?type=papers&publisher=cvpr&sort=new) or browse the virtual posters on [CVPR](https://cvpr.thecvf.com/virtual/2025/papers.html).

Note: [Bytez](https://bytez.com/models) is working to make CVPR vision models <b>accessible for free</b> through our Inference API. More to come ✨


## Paper List

| Paper Title | TLDR | Virtual Poster | Interactive Paper (Bytez) |
|-------------|-----------------|----------------|---------------------------|
| [robotwin: dual-arm robot benchmark with generative digital twins](https://cvpr.thecvf.com/virtual/2025/poster/33419) | Introduces a benchmark using generative digital twins to evaluate dual-arm robotic manipulation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33419) | [Bytez](https://bytez.com/docs/cvpr/33419) |
| [prof. robot: differentiable robot rendering without static and self-collisions](https://cvpr.thecvf.com/virtual/2025/poster/33622) | Proposes a differentiable rendering method to simulate robot motion avoiding collisions. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33622) | [Bytez](https://bytez.com/docs/cvpr/33622) |
| [lift3d policy: lifting 2d foundation models for robust 3d robotic manipulation](https://cvpr.thecvf.com/virtual/2025/poster/34011) | Adapts 2D pretrained models to improve robustness in 3D robotic manipulation tasks. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34011) | [Bytez](https://bytez.com/docs/cvpr/34011) |
| [robospatial: teaching spatial understanding to 2d and 3d vision-language models for robotics](https://cvpr.thecvf.com/virtual/2025/poster/32478) | Enhances vision-language models with spatial reasoning capabilities for robotics. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32478) | [Bytez](https://bytez.com/docs/cvpr/32478) |
| [a data-centric revisit of pre-trained vision models for robot learning](https://cvpr.thecvf.com/virtual/2025/poster/34199) | Re-examines the impact of data-centric approaches on pre-trained vision models for robots. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34199) | [Bytez](https://bytez.com/docs/cvpr/34199) |
| [autourdf: unsupervised robot modeling from point cloud frames using cluster registration](https://cvpr.thecvf.com/virtual/2025/poster/33613) | Uses unsupervised cluster registration of point clouds for robot modeling. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33613) | [Bytez](https://bytez.com/docs/cvpr/33613) |
| [robopepp: vision-based robot pose and joint angle estimation through embedding predictive pre-training](https://cvpr.thecvf.com/virtual/2025/poster/32501) | Embedding predictive pre-training enhances vision-based robot pose and joint angle estimation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32501) | [Bytez](https://bytez.com/docs/cvpr/32501) |
| [3d-mvp: 3d multiview pretraining for manipulation](https://cvpr.thecvf.com/virtual/2025/poster/32920) | Introduces a multiview 3D pretraining method to improve manipulation skills. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32920) | [Bytez](https://bytez.com/docs/cvpr/32920) |
| [mitigating the human-robot domain discrepancy in visual pre-training for robotic manipulation](https://cvpr.thecvf.com/virtual/2025/poster/32537) | Addresses domain gap in visuals between humans and robots to enhance manipulation pre-training. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32537) | [Bytez](https://bytez.com/docs/cvpr/32537) |
| [spatial-temporal graph diffusion policy with kinematic modeling for bimanual robotic manipulation](https://cvpr.thecvf.com/virtual/2025/poster/33065) | Combines graph diffusion and kinematic modeling for coordinated bimanual manipulation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33065) | [Bytez](https://bytez.com/docs/cvpr/33065) |
| [omnimanip: towards general robotic manipulation via object-centric interaction primitives as spatial constraints](https://cvpr.thecvf.com/virtual/2025/poster/33901) | Develops general manipulation techniques using object-centric spatial interaction primitives. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33901) | [Bytez](https://bytez.com/docs/cvpr/33901) |
| [robobrain: a unified brain model for robotic manipulation from abstract to concrete](https://cvpr.thecvf.com/virtual/2025/poster/34105) | Proposes a unified brain-inspired model linking abstract reasoning to concrete manipulation actions. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34105) | [Bytez](https://bytez.com/docs/cvpr/34105) |
| [phoenix: a motion-based self-reflection framework for fine-grained robotic action correction](https://cvpr.thecvf.com/virtual/2025/poster/32789) | Introduces a framework where robots self-reflect on motion for precise action correction. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32789) | [Bytez](https://bytez.com/docs/cvpr/32789) |
| [let humanoids hike! integrative skill development on complex trails](https://cvpr.thecvf.com/virtual/2025/poster/34565) | Explores humanoid skill development for navigating complex hiking trails. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34565) | [Bytez](https://bytez.com/docs/cvpr/34565) |
| [towards autonomous micromobility through scalable urban simulation](https://cvpr.thecvf.com/virtual/2025/poster/34324) | Develops scalable urban simulations to aid autonomous micromobility systems. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34324) | [Bytez](https://bytez.com/docs/cvpr/34324) |
| [flowram: grounding flow matching policy with region-aware mamba framework for robotic manipulation](https://cvpr.thecvf.com/virtual/2025/poster/33579) | Introduces a flow matching policy grounded with region-aware frameworks for manipulation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33579) | [Bytez](https://bytez.com/docs/cvpr/33579) |
| [g3flow: generative 3d semantic flow for pose-aware and generalizable object manipulation](https://cvpr.thecvf.com/virtual/2025/poster/34550) | Proposes a generative 3D semantic flow model for pose-aware object manipulation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34550) | [Bytez](https://bytez.com/docs/cvpr/34550) |
| [vidbot: learning generalizable 3d actions from in-the-wild 2d human videos for zero-shot robotic manipulation](https://cvpr.thecvf.com/virtual/2025/poster/32561) | Leverages 2D human videos to learn generalizable 3D robotic actions without retraining. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32561) | [Bytez](https://bytez.com/docs/cvpr/32561) |
| [genmanip: llm-driven simulation for generalizable instruction-following manipulation](https://cvpr.thecvf.com/virtual/2025/poster/33632) | Uses large language model driven simulation for instruction-following robotic manipulation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33632) | [Bytez](https://bytez.com/docs/cvpr/33632) |
| [robotic visual instruction](https://cvpr.thecvf.com/virtual/2025/poster/34129) | Develops systems enabling robots to learn tasks from visual instructions. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34129) | [Bytez](https://bytez.com/docs/cvpr/34129) |
| [reasoning in visual navigation of end-to-end trained agents: a dynamical systems approach](https://cvpr.thecvf.com/virtual/2025/poster/33019) | Applies dynamical systems theory to improve reasoning in end-to-end visual navigation agents. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33019) | [Bytez](https://bytez.com/docs/cvpr/33019) |
| [maniptrans: efficient dexterous bimanual manipulation transfer via residual learning](https://cvpr.thecvf.com/virtual/2025/poster/32548) | Uses residual learning to transfer dexterous bimanual manipulation skills efficiently. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32548) | [Bytez](https://bytez.com/docs/cvpr/32548) |
| [two by two: learning multi-task pairwise objects assembly for generalizable robot manipulation](https://cvpr.thecvf.com/virtual/2025/poster/33946) | Proposes multi-task learning for pairwise object assembly to improve manipulation generalization. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33946) | [Bytez](https://bytez.com/docs/cvpr/33946) |
| [think small, act big: primitive prompt learning for lifelong robot manipulation](https://cvpr.thecvf.com/virtual/2025/poster/33193) | Introduces primitive prompt learning to enable lifelong robot manipulation skills. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33193) | [Bytez](https://bytez.com/docs/cvpr/33193) |
| [universal actions for enhanced embodied foundation models](https://cvpr.thecvf.com/virtual/2025/poster/34078) | Defines universal actions to improve embodied AI foundation models for robotics. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34078) | [Bytez](https://bytez.com/docs/cvpr/34078) |
| [physvlm: enabling visual language models to understand robotic physical reachability](https://cvpr.thecvf.com/virtual/2025/poster/35212) | Enhances visual language models to predict physically reachable areas for robots. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35212) | [Bytez](https://bytez.com/docs/cvpr/35212) |
| [unigrasptransformer: simplified policy distillation for scalable dexterous robotic grasping](https://cvpr.thecvf.com/virtual/2025/poster/34554) | Simplifies policy distillation to scale dexterous robotic grasping with transformers. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34554) | [Bytez](https://bytez.com/docs/cvpr/34554) |
| [roboground: robotic manipulation with grounded vision-language priors](https://cvpr.thecvf.com/virtual/2025/poster/34049) | Integrates grounded vision-language priors to enhance robotic manipulation tasks. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34049) | [Bytez](https://bytez.com/docs/cvpr/34049) |
| [cap-net: a unified network for 6d pose and size estimation of categorical articulated parts from a single rgb-d image](https://cvpr.thecvf.com/virtual/2025/poster/34668) | Estimates 6D pose and size of articulated object parts from RGB-D images using a unified network. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34668) | [Bytez](https://bytez.com/docs/cvpr/34668) |
| [pdfactor: learning tri-perspective view policy diffusion field for multi-task robotic manipulation](https://cvpr.thecvf.com/virtual/2025/poster/33943) | Learns policies using tri-perspective view diffusion fields for diverse robotic tasks. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33943) | [Bytez](https://bytez.com/docs/cvpr/33943) |
| [mobileh2r: learning generalizable human to mobile robot handover exclusively from scalable and diverse synthetic data](https://cvpr.thecvf.com/virtual/2025/poster/35091) | Trains human-to-robot handover skills using diverse synthetic data for generalization. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35091) | [Bytez](https://bytez.com/docs/cvpr/35091) |
| [skillmimic: learning basketball interaction skills from demonstrations](https://cvpr.thecvf.com/virtual/2025/poster/34791) | Uses demonstration learning to acquire basketball interaction skills for robots. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34791) | [Bytez](https://bytez.com/docs/cvpr/34791) |
| [object-centric prompt-driven vision-language-action model for robotic manipulation](https://cvpr.thecvf.com/virtual/2025/poster/34522) | Employs object-centric prompts to drive vision-language-action models in robotics. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34522) | [Bytez](https://bytez.com/docs/cvpr/34522) |
| [momanipvla: transferring vision-language-action models for general mobile manipulation](https://cvpr.thecvf.com/virtual/2025/poster/32433) | Transfers vision-language-action models to improve mobile robot manipulation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32433) | [Bytez](https://bytez.com/docs/cvpr/32433) |
| [tartan imu: a light foundation model for inertial positioning in robotics](https://cvpr.thecvf.com/virtual/2025/poster/33873) | Proposes a lightweight foundation model for inertial positioning in robotics. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33873) | [Bytez](https://bytez.com/docs/cvpr/33873) |
| [grove: a generalized reward for learning open-vocabulary physical skill](https://cvpr.thecvf.com/virtual/2025/poster/35222) | Develops a generalized reward system to learn open-vocabulary physical skills. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35222) | [Bytez](https://bytez.com/docs/cvpr/35222) |
| [neural motion simulator pushing the limit of world models in reinforcement learning](https://cvpr.thecvf.com/virtual/2025/poster/34450) | Presents a neural motion simulator advancing world models for reinforcement learning. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34450) | [Bytez](https://bytez.com/docs/cvpr/34450) |
| [intermimic: towards universal whole-body control for physics-based human-object interactions](https://cvpr.thecvf.com/virtual/2025/poster/33421) | Works toward universal whole-body control for human-object interaction in physics simulations. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33421) | [Bytez](https://bytez.com/docs/cvpr/33421) |
| [zerograsp: zero-shot shape reconstruction enabled robotic grasping](https://cvpr.thecvf.com/virtual/2025/poster/32440) | Enables zero-shot robotic grasping by reconstructing object shape on the fly. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32440) | [Bytez](https://bytez.com/docs/cvpr/32440) |
| [code-as-monitor: constraint-aware visual programming for reactive and proactive robotic failure detection](https://cvpr.thecvf.com/virtual/2025/poster/34558) | Uses visual programming to monitor and detect robotic failures proactively. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34558) | [Bytez](https://bytez.com/docs/cvpr/34558) |
| [graphmimic: graph-to-graphs generative modeling from videos for policy learning](https://cvpr.thecvf.com/virtual/2025/poster/34942) | Generates graph representations from videos to aid policy learning. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34942) | [Bytez](https://bytez.com/docs/cvpr/34942) |
| [robosense: large-scale dataset and benchmark for egocentric robot perception and navigation in crowded and unstructured environments](https://cvpr.thecvf.com/virtual/2025/poster/33546) | Provides a large dataset and benchmark for egocentric robot perception/navigation in complex settings. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33546) | [Bytez](https://bytez.com/docs/cvpr/33546) |
| [magma: a foundation model for multimodal ai agents](https://cvpr.thecvf.com/virtual/2025/poster/33563) | Introduces a foundation model supporting multimodal AI agents for robotics. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33563) | [Bytez](https://bytez.com/docs/cvpr/33563) |
| [dynscene: scalable generation of dynamic robotic manipulation scenes for embodied ai](https://cvpr.thecvf.com/virtual/2025/poster/33953) | Scales generation of dynamic scenes for embodied AI robotic manipulation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33953) | [Bytez](https://bytez.com/docs/cvpr/33953) |
| [dexhanddiff: interaction-aware diffusion planning for adaptive dexterous manipulation](https://cvpr.thecvf.com/virtual/2025/poster/32953) | Uses diffusion planning aware of interactions for adaptive dexterous manipulation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32953) | [Bytez](https://bytez.com/docs/cvpr/32953) |
| [r2c: mapping room to chessboard to unlock llm as low-level action planner](https://cvpr.thecvf.com/virtual/2025/poster/34506) | Maps spatial environments to chessboard representations to enable LLMs as action planners. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34506) | [Bytez](https://bytez.com/docs/cvpr/34506) |
| [tra-moe: learning trajectory prediction model from multiple domains for adaptive policy conditioning](https://cvpr.thecvf.com/virtual/2025/poster/34256) | Learns multi-domain trajectory prediction for adaptive robotic policy conditioning. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34256) | [Bytez](https://bytez.com/docs/cvpr/34256) |
| [towards visual discrimination and reasoning of real-world physical dynamics: physics-grounded anomaly detection](https://cvpr.thecvf.com/virtual/2025/poster/33639) | Uses physics-grounded models to detect anomalies in physical dynamics visually. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33639) | [Bytez](https://bytez.com/docs/cvpr/33639) |
| [afforddp: generalizable diffusion policy with transferable affordance](https://cvpr.thecvf.com/virtual/2025/poster/33395) | Develops a diffusion policy leveraging transferable affordances for generalization. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33395) | [Bytez](https://bytez.com/docs/cvpr/33395) |
| [generating 6dof object manipulation trajectories from action description in egocentric vision](https://cvpr.thecvf.com/virtual/2025/poster/34183) | Generates 6DoF manipulation trajectories based on egocentric action descriptions. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34183) | [Bytez](https://bytez.com/docs/cvpr/34183) |
| [taste-rob: advancing video generation of task-oriented hand-object interaction for generalizable robotic manipulation](https://cvpr.thecvf.com/virtual/2025/poster/35193) | Improves video generation of task-specific hand-object interactions for manipulation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35193) | [Bytez](https://bytez.com/docs/cvpr/35193) |
| [partrm: modeling part-level dynamics with large cross-state reconstruction model](https://cvpr.thecvf.com/virtual/2025/poster/32725) | Models dynamics at part-level using large reconstruction models across states. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32725) | [Bytez](https://bytez.com/docs/cvpr/32725) |
| [meshart: generating articulated meshes with structure-guided transformers](https://cvpr.thecvf.com/virtual/2025/poster/33295) | Uses transformers to generate articulated 3D meshes guided by structure. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33295) | [Bytez](https://bytez.com/docs/cvpr/33295) |
| [iaao: interactive affordance learning for articulated objects in 3d environments](https://cvpr.thecvf.com/virtual/2025/poster/33719) | Learns interactive affordances for articulated objects in 3D spaces. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33719) | [Bytez](https://bytez.com/docs/cvpr/33719) |
| [tokenhsi: unified synthesis of physical human-scene interactions through task tokenization](https://cvpr.thecvf.com/virtual/2025/poster/33876) | Synthesizes human-scene interactions using task tokenization in a unified framework. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33876) | [Bytez](https://bytez.com/docs/cvpr/33876) |
| [cot-vla: visual chain-of-thought reasoning for vision-language-action models](https://cvpr.thecvf.com/virtual/2025/poster/33233) | Introduces chain-of-thought reasoning in vision-language-action models. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33233) | [Bytez](https://bytez.com/docs/cvpr/33233) |
| [pidloc: cross-view pose optimization network inspired by pid controllers](https://cvpr.thecvf.com/virtual/2025/poster/33649) | Proposes a pose optimization network inspired by PID control theory for localization. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33649) | [Bytez](https://bytez.com/docs/cvpr/33649) |
| [fiction: 4d future interaction prediction from video](https://cvpr.thecvf.com/virtual/2025/poster/34464) | Predicts future 4D human-object interactions from video data. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34464) | [Bytez](https://bytez.com/docs/cvpr/34464) |
| [how do i do that? synthesizing 3d hand motion and contacts for everyday interactions](https://cvpr.thecvf.com/virtual/2025/poster/33490) | Synthesizes 3D hand motion and contact points for everyday tasks. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33490) | [Bytez](https://bytez.com/docs/cvpr/33490) |
| [from multimodal llms to generalist embodied agents: methods and lessons](https://cvpr.thecvf.com/virtual/2025/poster/33823) | Surveys methods to build generalist embodied agents from multimodal LLMs. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33823) | [Bytez](https://bytez.com/docs/cvpr/33823) |
| [bimart: a unified approach for the synthesis of 3d bimanual interaction with articulated objects](https://cvpr.thecvf.com/virtual/2025/poster/34738) | Synthesizes 3D bimanual interactions with articulated objects using a unified approach. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34738) | [Bytez](https://bytez.com/docs/cvpr/34738) |
| [category-agnostic neural object rigging](https://cvpr.thecvf.com/virtual/2025/poster/33567) | Develops neural rigging methods that work across object categories. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33567) | [Bytez](https://bytez.com/docs/cvpr/33567) |
| [tango: training-free embodied ai agents for open-world tasks](https://cvpr.thecvf.com/virtual/2025/poster/34559) | Proposes training-free AI agents for open-world embodied tasks. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34559) | [Bytez](https://bytez.com/docs/cvpr/34559) |
| [rocket-1: mastering open-world interaction with visual-temporal context prompting](https://cvpr.thecvf.com/virtual/2025/poster/34772) | Uses visual-temporal prompts to master interactions in open-world environments. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34772) | [Bytez](https://bytez.com/docs/cvpr/34772) |
| [crocodl: cross-device collaborative dataset for localization](https://cvpr.thecvf.com/virtual/2025/poster/32865) | Provides a cross-device dataset to improve collaborative localization. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32865) | [Bytez](https://bytez.com/docs/cvpr/32865) |
| [handos: 3d hand reconstruction in one stage](https://cvpr.thecvf.com/virtual/2025/poster/33879) | Proposes a one-stage method for 3D hand reconstruction. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33879) | [Bytez](https://bytez.com/docs/cvpr/33879) |
| [multi-modal knowledge distillation-based human trajectory forecasting](https://cvpr.thecvf.com/virtual/2025/poster/33379) | Uses multimodal knowledge distillation to forecast human trajectories. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33379) | [Bytez](https://bytez.com/docs/cvpr/33379) |
| [citywalker: learning embodied urban navigation from web-scale videos](https://cvpr.thecvf.com/virtual/2025/poster/33371) | Learns urban navigation skills from large-scale video data for embodied agents. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33371) | [Bytez](https://bytez.com/docs/cvpr/33371) |
| [ske-layout: spatial knowledge enhanced layout generation with llms](https://cvpr.thecvf.com/virtual/2025/poster/35149) | Enhances layout generation using spatial knowledge integrated with large language models. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35149) | [Bytez](https://bytez.com/docs/cvpr/35149) |
| [rethinking correspondence-based category-level object pose estimation](https://cvpr.thecvf.com/virtual/2025/poster/34619) | Revisits category-level object pose estimation via correspondence learning. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34619) | [Bytez](https://bytez.com/docs/cvpr/34619) |
| [structure-aware correspondence learning for relative pose estimation](https://cvpr.thecvf.com/virtual/2025/poster/34892) | Incorporates structure-awareness into correspondence learning for pose estimation. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34892) | [Bytez](https://bytez.com/docs/cvpr/34892) |
| [learning physics-based full-body human reaching and grasping from brief walking references](https://cvpr.thecvf.com/virtual/2025/poster/34983) | Learns full-body reaching and grasping motions from brief reference motions. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34983) | [Bytez](https://bytez.com/docs/cvpr/34983) |
| [leveraging global stereo consistency for category-level shape and 6d pose estimation from stereo images](https://cvpr.thecvf.com/virtual/2025/poster/33782) | Uses stereo image consistency to estimate shape and 6D pose at category level. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33782) | [Bytez](https://bytez.com/docs/cvpr/33782) |
| [semgeomo: dynamic contextual human motion generation with semantic and geometric guidance](https://cvpr.thecvf.com/virtual/2025/poster/33804) | Generates human motion dynamically with semantic and geometric context. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33804) | [Bytez](https://bytez.com/docs/cvpr/33804) |
| [chainhoi: joint-based kinematic chain modeling for human-object interaction generation](https://cvpr.thecvf.com/virtual/2025/poster/33753) | Models human-object interactions with joint-based kinematic chains. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33753) | [Bytez](https://bytez.com/docs/cvpr/33753) |
| [lal: enhancing 3d human motion prediction with latency-aware auxiliary learning](https://cvpr.thecvf.com/virtual/2025/poster/32536) | Improves 3D human motion prediction using latency-aware auxiliary learning. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32536) | [Bytez](https://bytez.com/docs/cvpr/32536) |
| [poly-autoregressive prediction for modeling interactions](https://cvpr.thecvf.com/virtual/2025/poster/34430) | Uses poly-autoregressive models for capturing complex interactions. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34430) | [Bytez](https://bytez.com/docs/cvpr/34430) |
| [hand-held object reconstruction from rgb video with dynamic interaction](https://cvpr.thecvf.com/virtual/2025/poster/33963) | Reconstructs handheld objects from RGB video considering dynamic interactions. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33963) | [Bytez](https://bytez.com/docs/cvpr/33963) |
| [dyn-hamr: recovering 4d interacting hand motion from a dynamic camera](https://cvpr.thecvf.com/virtual/2025/poster/33016) | Recovers 4D hand motion from videos captured by dynamic cameras. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33016) | [Bytez](https://bytez.com/docs/cvpr/33016) |
| [gce-pose: global context enhancement for category-level object pose estimation](https://cvpr.thecvf.com/virtual/2025/poster/35180) | Enhances object pose estimation by integrating global context. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35180) | [Bytez](https://bytez.com/docs/cvpr/35180) |
| [guiding human-object interactions with rich geometry and relations](https://cvpr.thecvf.com/virtual/2025/poster/32907) | Uses detailed geometry and relational data to guide human-object interactions. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32907) | [Bytez](https://bytez.com/docs/cvpr/32907) |
| [monotakd: teaching assistant knowledge distillation for monocular 3d object detection](https://cvpr.thecvf.com/virtual/2025/poster/34369) | Applies knowledge distillation to improve monocular 3D object detection. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34369) | [Bytez](https://bytez.com/docs/cvpr/34369) |
| [comrope: scalable and robust rotary position embedding parameterized by trainable commuting angle matrices](https://cvpr.thecvf.com/virtual/2025/poster/32419) | Introduces a novel rotary position embedding method using angle matrices. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32419) | [Bytez](https://bytez.com/docs/cvpr/32419) |
| [boe-vit: boosting orientation estimation with equivariance in self-supervised 3d subtomogram alignment](https://cvpr.thecvf.com/virtual/2025/poster/35236) | Improves orientation estimation by enforcing equivariance in self-supervised alignment. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35236) | [Bytez](https://bytez.com/docs/cvpr/35236) |
| [activating sparse part concepts for 3d class incremental learning](https://cvpr.thecvf.com/virtual/2025/poster/32851) | Activates sparse part concepts to enable incremental learning in 3D classification. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32851) | [Bytez](https://bytez.com/docs/cvpr/32851) |
| [eee-bench: a comprehensive multimodal electrical and electronics engineering benchmark](https://cvpr.thecvf.com/virtual/2025/poster/35039) | Presents a multimodal benchmark dataset focused on electrical engineering tasks. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35039) | [Bytez](https://bytez.com/docs/cvpr/35039) |
| [neuron: learning context-aware evolving representations for zero-shot skeleton action recognition](https://cvpr.thecvf.com/virtual/2025/poster/34553) | Learns evolving, context-aware representations to enable zero-shot skeleton action recognition. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34553) | [Bytez](https://bytez.com/docs/cvpr/34553) |
| [open-vocabulary functional 3d scene graphs for real-world indoor spaces](https://cvpr.thecvf.com/virtual/2025/poster/34720) | Builds functional 3D scene graphs with open vocabulary understanding for indoor spaces. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34720) | [Bytez](https://bytez.com/docs/cvpr/34720) |
| [escape: equivariant shape completion via anchor point encoding](https://cvpr.thecvf.com/virtual/2025/poster/32806) | Uses anchor point encoding to perform equivariant 3D shape completion. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32806) | [Bytez](https://bytez.com/docs/cvpr/32806) |
| [unigoal: towards universal zero-shot goal-oriented navigation](https://cvpr.thecvf.com/virtual/2025/poster/34649) | Aims for universal zero-shot goal-directed navigation across environments. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34649) | [Bytez](https://bytez.com/docs/cvpr/34649) |
| [functionality understanding and segmentation in 3d scenes](https://cvpr.thecvf.com/virtual/2025/poster/33812) | Studies segmentation and understanding of functionality in 3D scenes. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33812) | [Bytez](https://bytez.com/docs/cvpr/33812) |
| [mast3r-slam: real-time dense slam with 3d reconstruction priors](https://cvpr.thecvf.com/virtual/2025/poster/34871) | Proposes a real-time dense SLAM system enhanced by 3D reconstruction priors. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34871) | [Bytez](https://bytez.com/docs/cvpr/34871) |
| [recovering dynamic 3d sketches from videos](https://cvpr.thecvf.com/virtual/2025/poster/34062) | Recovers dynamic 3D sketches of scenes from video inputs. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34062) | [Bytez](https://bytez.com/docs/cvpr/34062) |
| [latte-mv: learning to anticipate table tennis hits from monocular videos](https://cvpr.thecvf.com/virtual/2025/poster/33442) | Anticipates table tennis hits by learning from monocular video footage. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33442) | [Bytez](https://bytez.com/docs/cvpr/33442) |
| [probing the mid-level vision capabilities of self-supervised learning](https://cvpr.thecvf.com/virtual/2025/poster/33776) | Investigates mid-level visual features learned via self-supervision. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33776) | [Bytez](https://bytez.com/docs/cvpr/33776) |
| [horp: human-object relation priors guided hoi detection](https://cvpr.thecvf.com/virtual/2025/poster/34697) | Enhances human-object interaction detection with relation priors. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34697) | [Bytez](https://bytez.com/docs/cvpr/34697) |
| [ecbench: can multi-modal foundation models understand the egocentric world? a holistic embodied cognition benchmark](https://cvpr.thecvf.com/virtual/2025/poster/33904) | Benchmarks multimodal foundation models on egocentric embodied cognition tasks. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33904) | [Bytez](https://bytez.com/docs/cvpr/33904) |
| [cross-modal distillation for 2d/3d multi-object discovery from 2d motion](https://cvpr.thecvf.com/virtual/2025/poster/33825) | Uses cross-modal distillation to detect multiple objects in 2D/3D from motion cues. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33825) | [Bytez](https://bytez.com/docs/cvpr/33825) |
| [crisp: object pose and shape estimation with test-time adaptation](https://cvpr.thecvf.com/virtual/2025/poster/35220) | Improves pose and shape estimation by adapting models at test time. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35220) | [Bytez](https://bytez.com/docs/cvpr/35220) |
| [exploration-driven generative interactive environments](https://cvpr.thecvf.com/virtual/2025/poster/33998) | Generates interactive environments driven by exploration objectives. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33998) | [Bytez](https://bytez.com/docs/cvpr/33998) |
| [on-device self-supervised learning of low-latency monocular depth from only events](https://cvpr.thecvf.com/virtual/2025/poster/35185) | Enables low-latency monocular depth learning on-device from event data. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35185) | [Bytez](https://bytez.com/docs/cvpr/35185) |
| [drawer: digital reconstruction and articulation with environment realism](https://cvpr.thecvf.com/virtual/2025/poster/33868) | Performs digital reconstruction with articulated realism in environments. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33868) | [Bytez](https://bytez.com/docs/cvpr/33868) |
| [crossover: 3d scene cross-modal alignment](https://cvpr.thecvf.com/virtual/2025/poster/34960) | Aligns 3D scenes across multiple modalities. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34960) | [Bytez](https://bytez.com/docs/cvpr/34960) |
| [timotion: temporal and interactive framework for efficient human-human motion generation](https://cvpr.thecvf.com/virtual/2025/poster/32570) | Creates efficient temporal models for interactive human-human motion synthesis. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32570) | [Bytez](https://bytez.com/docs/cvpr/32570) |
| [finephys: fine-grained human action generation by explicitly incorporating physical laws for effective skeletal guidance](https://cvpr.thecvf.com/virtual/2025/poster/33553) | Generates human actions guided by physical laws for skeletal realism. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33553) | [Bytez](https://bytez.com/docs/cvpr/33553) |
| [homogeneous dynamics space for heterogeneous humans](https://cvpr.thecvf.com/virtual/2025/poster/34346) | Models human motion in a homogeneous dynamics space despite human heterogeneity. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34346) | [Bytez](https://bytez.com/docs/cvpr/34346) |
| [from sparse signal to smooth motion: real-time motion generation with rolling prediction models](https://cvpr.thecvf.com/virtual/2025/poster/32843) | Generates smooth motions in real time from sparse input signals using rolling prediction. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32843) | [Bytez](https://bytez.com/docs/cvpr/32843) |
| [videoworld: exploring knowledge learning from unlabeled videos](https://cvpr.thecvf.com/virtual/2025/poster/35126) | Explores how AI can learn world knowledge from unlabeled video data. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35126) | [Bytez](https://bytez.com/docs/cvpr/35126) |
| [bigs: bimanual category-agnostic interaction reconstruction from monocular videos via 3d gaussian splatting](https://cvpr.thecvf.com/virtual/2025/poster/34060) | Reconstructs bimanual interactions from monocular video using 3D gaussian splatting. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34060) | [Bytez](https://bytez.com/docs/cvpr/34060) |
| [microvqa: a multimodal reasoning benchmark for microscopy-based scientific research](https://cvpr.thecvf.com/virtual/2025/poster/32974) | Provides a benchmark for multimodal reasoning in microscopy scientific tasks. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32974) | [Bytez](https://bytez.com/docs/cvpr/32974) |
| [spatial457: a diagnostic benchmark for 6d spatial reasoning of large mutimodal models](https://cvpr.thecvf.com/virtual/2025/poster/33612) | Offers a benchmark for 6D spatial reasoning ability in large multimodal models. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33612) | [Bytez](https://bytez.com/docs/cvpr/33612) |
| [artformer: controllable generation of diverse 3d articulated objects](https://cvpr.thecvf.com/virtual/2025/poster/33211) | Enables controllable generation of diverse articulated 3D objects. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33211) | [Bytez](https://bytez.com/docs/cvpr/33211) |
| [revealing key details to see differences: a novel prototypical perspective for skeleton-based action recognition](https://cvpr.thecvf.com/virtual/2025/poster/32933) | Proposes a novel prototypical method highlighting key details for skeleton action recognition. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32933) | [Bytez](https://bytez.com/docs/cvpr/32933) |
| [gazing into missteps: leveraging eye-gaze for unsupervised mistake detection in egocentric videos of skilled human activities](https://cvpr.thecvf.com/virtual/2025/poster/32832) | Uses eye-gaze data to detect mistakes unsupervised in skilled human activity videos. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32832) | [Bytez](https://bytez.com/docs/cvpr/32832) |
| [learning partonomic 3d reconstruction from image collections](https://cvpr.thecvf.com/virtual/2025/poster/33556) | Learns part-level 3D reconstruction from collections of images. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33556) | [Bytez](https://bytez.com/docs/cvpr/33556) |
| [vid2sim: realistic and interactive simulation from video for urban navigation](https://cvpr.thecvf.com/virtual/2025/poster/32747) | Converts video data into realistic interactive urban navigation simulations. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32747) | [Bytez](https://bytez.com/docs/cvpr/32747) |
| [easyhoi: unleashing the power of large models for reconstructing hand-object interactions in the wild](https://cvpr.thecvf.com/virtual/2025/poster/34010) | Uses large models to reconstruct hand-object interactions in natural settings. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34010) | [Bytez](https://bytez.com/docs/cvpr/34010) |
| [certified human trajectory prediction](https://cvpr.thecvf.com/virtual/2025/poster/34812) | Provides certified guarantees on predicted human trajectories. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34812) | [Bytez](https://bytez.com/docs/cvpr/34812) |
| [4dtam: non-rigid tracking and mapping via dynamic surface gaussians](https://cvpr.thecvf.com/virtual/2025/poster/32594) | Tracks and maps non-rigid scenes using dynamic surface Gaussian models. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32594) | [Bytez](https://bytez.com/docs/cvpr/32594) |
| [sasep: saliency-aware structured separation of geometry and feature for open set learning on point clouds](https://cvpr.thecvf.com/virtual/2025/poster/33889) | Separates geometry and features in point clouds for open set learning with saliency awareness. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33889) | [Bytez](https://bytez.com/docs/cvpr/33889) |
| [cholectrack20: a multi-perspective tracking dataset for surgical tools](https://cvpr.thecvf.com/virtual/2025/poster/34130) | Provides a multi-perspective dataset for tracking surgical tools. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34130) | [Bytez](https://bytez.com/docs/cvpr/34130) |
| [alien: implicit neural representations for human motion prediction under arbitrary latency](https://cvpr.thecvf.com/virtual/2025/poster/34836) | Predicts human motion using implicit neural representations handling latency. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34836) | [Bytez](https://bytez.com/docs/cvpr/34836) |
| [ua-pose: uncertainty-aware 6d object pose estimation and online object completion with partial references](https://cvpr.thecvf.com/virtual/2025/poster/34276) | Estimates object pose with uncertainty and completes partial objects online. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34276) | [Bytez](https://bytez.com/docs/cvpr/34276) |
| [magic-slam: multi-agent gaussian globally consistent  slam](https://cvpr.thecvf.com/virtual/2025/poster/33967) | Introduces a multi-agent SLAM approach with globally consistent Gaussian modeling. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33967) | [Bytez](https://bytez.com/docs/cvpr/33967) |
| [humocon: concept discovery for human motion understanding](https://cvpr.thecvf.com/virtual/2025/poster/34479) | Discovers concepts to enhance human motion understanding. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34479) | [Bytez](https://bytez.com/docs/cvpr/34479) |
| [cospace: benchmarking continuous space perception ability for vision-language models](https://cvpr.thecvf.com/virtual/2025/poster/32810) | Benchmarks continuous space perception for vision-language models. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32810) | [Bytez](https://bytez.com/docs/cvpr/32810) |
| [human motion instruction tuning](https://cvpr.thecvf.com/virtual/2025/poster/35018) | Tunes models to follow human motion instructions more effectively. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35018) | [Bytez](https://bytez.com/docs/cvpr/35018) |
| [beyond human perception: understanding multi-object world from monocular view](https://cvpr.thecvf.com/virtual/2025/poster/34458) | Understands multi-object scenes from monocular visual input beyond human perception. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34458) | [Bytez](https://bytez.com/docs/cvpr/34458) |
| [tokenmotion: decoupled motion control via token disentanglement for human-centric video generation](https://cvpr.thecvf.com/virtual/2025/poster/34292) | Controls human-centric video generation through disentangled motion tokens. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34292) | [Bytez](https://bytez.com/docs/cvpr/34292) |
| [checkmanual: a new challenge and benchmark for manual-based appliance manipulation](https://cvpr.thecvf.com/virtual/2025/poster/33824) | Introduces a benchmark for manipulation of appliances using manuals. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33824) | [Bytez](https://bytez.com/docs/cvpr/33824) |
| [vsnet: focusing on the linguistic characteristics of sign language](https://cvpr.thecvf.com/virtual/2025/poster/33549) | Analyzes linguistic features in sign language via VSNet. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33549) | [Bytez](https://bytez.com/docs/cvpr/33549) |
| [collaborative tree search for enhancing embodied multi-agent collaboration](https://cvpr.thecvf.com/virtual/2025/poster/32902) | Uses collaborative tree search to improve multi-agent embodied collaboration. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32902) | [Bytez](https://bytez.com/docs/cvpr/32902) |
| [continuous 3d perception model with persistent state](https://cvpr.thecvf.com/virtual/2025/poster/34897) | Develops a continuous 3D perception model maintaining persistent state. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34897) | [Bytez](https://bytez.com/docs/cvpr/34897) |
| [vision-guided action: enhancing 3d human motion prediction with gaze-informed affordance in 3d scenes](https://cvpr.thecvf.com/virtual/2025/poster/33155) | Improves 3D human motion prediction using gaze-informed affordances. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33155) | [Bytez](https://bytez.com/docs/cvpr/33155) |
| [interdyn: controllable interactive dynamics with video diffusion models](https://cvpr.thecvf.com/virtual/2025/poster/33892) | Models controllable interactive dynamics via video diffusion. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33892) | [Bytez](https://bytez.com/docs/cvpr/33892) |
| [dragin3d: image editing by dragging in 3d space](https://cvpr.thecvf.com/virtual/2025/poster/34583) | Enables 3D image editing by dragging controls within 3D space. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34583) | [Bytez](https://bytez.com/docs/cvpr/34583) |
| [unistd: towards unified spatio-temporal learning across diverse disciplines](https://cvpr.thecvf.com/virtual/2025/poster/32957) | Proposes a unified model for spatio-temporal learning across domains. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32957) | [Bytez](https://bytez.com/docs/cvpr/32957) |
| [h-more: learning human-centric motion representation for action analysis](https://cvpr.thecvf.com/virtual/2025/poster/32845) | Learns motion representations centered on humans for action analysis. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32845) | [Bytez](https://bytez.com/docs/cvpr/32845) |
| [closed-loop supervised fine-tuning of tokenized traffic models](https://cvpr.thecvf.com/virtual/2025/poster/33174) | Fine-tunes traffic prediction models in closed-loop supervision with tokenized inputs. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33174) | [Bytez](https://bytez.com/docs/cvpr/33174) |
| [grae-3dmot: geometry relation-aware encoder for online 3d multi-object tracking](https://cvpr.thecvf.com/virtual/2025/poster/35168) | Encodes geometry relations to improve online 3D multi-object tracking. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35168) | [Bytez](https://bytez.com/docs/cvpr/35168) |
| [echoworld: learning motion-aware world models for echocardiography probe guidance](https://cvpr.thecvf.com/virtual/2025/poster/34389) | Learns motion-aware models to guide echocardiography probes effectively. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34389) | [Bytez](https://bytez.com/docs/cvpr/34389) |
| [videogem: training-free action grounding in videos](https://cvpr.thecvf.com/virtual/2025/poster/34020) | Grounds actions in video data without additional training. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34020) | [Bytez](https://bytez.com/docs/cvpr/34020) |
| [reanimating images using neural representations of dynamic stimuli](https://cvpr.thecvf.com/virtual/2025/poster/34958) | Uses neural representations to reanimate static images dynamically. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34958) | [Bytez](https://bytez.com/docs/cvpr/34958) |
| [uncertainty meets diversity: a comprehensive active learning framework for indoor 3d object detection](https://cvpr.thecvf.com/virtual/2025/poster/34027) | Combines uncertainty and diversity for active learning in 3D object detection. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34027) | [Bytez](https://bytez.com/docs/cvpr/34027) |
| [hsi-gpt: a general-purpose large scene-motion-language model for human scene interaction](https://cvpr.thecvf.com/virtual/2025/poster/35243) | Proposes a large model combining scene, motion, and language for human-scene interactions. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35243) | [Bytez](https://bytez.com/docs/cvpr/35243) |
| [simulator hc: regression-based online simulation of starting problem-solution pairs for homotopy continuation in geometric vision](https://cvpr.thecvf.com/virtual/2025/poster/34868) | Uses regression to simulate homotopy continuation in geometric vision online. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34868) | [Bytez](https://bytez.com/docs/cvpr/34868) |
| [gem: a generalizable ego-vision multimodal world model for fine-grained ego-motion, object dynamics, and scene composition control](https://cvpr.thecvf.com/virtual/2025/poster/33119) | Introduces an ego-vision multimodal world model for fine-grained control. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33119) | [Bytez](https://bytez.com/docs/cvpr/33119) |
| [gigahands: a massive annotated dataset of bimanual hand activities](https://cvpr.thecvf.com/virtual/2025/poster/32634) | Releases a large dataset of annotated bimanual hand activities. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32634) | [Bytez](https://bytez.com/docs/cvpr/32634) |
| [posetraj: pose-aware trajectory control in video diffusion](https://cvpr.thecvf.com/virtual/2025/poster/32939) | Controls trajectory in video diffusion models using pose information. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32939) | [Bytez](https://bytez.com/docs/cvpr/32939) |
| [logosp: local-global grouping of superpoints for unsupervised semantic segmentation of 3d point clouds](https://cvpr.thecvf.com/virtual/2025/poster/35030) | Proposes a method for semantic segmentation by grouping superpoints locally and globally. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/35030) | [Bytez](https://bytez.com/docs/cvpr/35030) |
| [pomp: physics-consistent motion generative model through phase manifolds](https://cvpr.thecvf.com/virtual/2025/poster/34291) | Generates motions consistent with physics using phase manifold modeling. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34291) | [Bytez](https://bytez.com/docs/cvpr/34291) |
| [pose priors from language models](https://cvpr.thecvf.com/virtual/2025/poster/34694) | Extracts pose priors from large language models for robotics. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/34694) | [Bytez](https://bytez.com/docs/cvpr/34694) |
| [articulatedgs: self-supervised digital twin modeling of articulated objects using 3d gaussian splatting](https://cvpr.thecvf.com/virtual/2025/poster/32589) | Creates self-supervised digital twins of articulated objects with 3D Gaussian splatting. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/32589) | [Bytez](https://bytez.com/docs/cvpr/32589) |
| [dexgrasp anything: towards universal robotic dexterous grasping with physics awareness](https://cvpr.thecvf.com/virtual/2025/poster/33280) | Proposes a physics-aware approach for universal dexterous robotic grasping across diverse objects and scenarios. | [CVPR](https://cvpr.thecvf.com/virtual/2025/poster/33280) | [Bytez](https://bytez.com/docs/arxiv/2503.08257/paper) |
